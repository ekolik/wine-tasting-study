{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b86cc73",
   "metadata": {},
   "source": [
    "# Blind Tasting (Grape Variety Guessing): Red Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513bf67",
   "metadata": {},
   "source": [
    "The goal of this work is to build a model that **predicts a wine's grape variety based on the tasting description** - this is what sommeliers call \"**blind tasting**\". In other words, we want to build a \"sommelier-model\". Besides making the prediction, we want the model to display the **main descriptors**, or **key words**, characteristic of the variety. In this notebook we will focus on red wines only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2998400",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525d312",
   "metadata": {},
   "source": [
    "First, we import the necessary **libraries and read the data**. For this task we will use the columns *desctiption* (our predictor variable) and *province* and *variety* columns (our target variables). See more explataions on these variables below.\n",
    "\n",
    "We already explored the data in the data exploration notebook (same repo) and know that it has a few full duplicates and a handful of missing values in the columns of our interest (*province* and *variety*). At this point we deal with them by simply dropping the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30d4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7714d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('winemag-data-130k-v2.csv')\n",
    "df.rename(columns={\"Unnamed: 0\": \"id\"}, inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset = df.columns.difference(['id']), inplace=True)\n",
    "df.dropna(subset=['province', 'variety'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38b847",
   "metadata": {},
   "source": [
    "Now we need to **prepare our predictor variable** - column *description*. \n",
    "\n",
    "First, we want to remove from this column any words that appear in the target columns (*province* and *variety*). Such words sometimes appear in the description because the tasters (who wrote these descriptions) didn't taste the wines blind, so they could mention the wines' variety or origin in the description. In our case, we want the descriptions to be as \"blind\" as possilbe and focus only on sensory parts of them.\n",
    "\n",
    "Since words are often be surrounded by commas, dots and dashes, we first replace these punctuation marks with spaces. Then we exclude *variety* and *province* words from *description*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e71e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.replace('[\\.\\,\\-]', ' ', regex = True, inplace = True )\n",
    "\n",
    "df['description'] = [' '.join(x for x in a.split(' ') if x not in set(b.split(' ')))\n",
    "                            for a, b in zip(df['description'], df['variety'])]\n",
    "\n",
    "df['description'] = [' '.join(x for x in a.split(' ') if x not in set(b.split(' ')))\n",
    "                            for a, b in zip(df['description'], df['province'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc4981",
   "metadata": {},
   "source": [
    "Now we **prepare our target variable** - combination of columns *province* and *variety*. \n",
    "\n",
    "By creating this combination, we'll be predicting the wine more accurately. For example, we'll predict that the wine is a \"Oregon Syrah\". And it's important to specify the wine's origin (not just the variety) because the same variety's wine can taste very different when it comes from different regions. \n",
    "\n",
    "We call this combination *prov_var* (new column) and display the top 60 potential classes by the number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b8a573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California_Pinot Noir                   6418\n",
       "California_Cabernet Sauvignon           5328\n",
       "California_Chardonnay                   4784\n",
       "Bordeaux_Bordeaux style Red Blend       4336\n",
       "Oregon_Pinot Noir                       2560\n",
       "Piedmont_Nebbiolo                       2478\n",
       "California_Zinfandel                    2458\n",
       "Burgundy_Chardonnay                     2130\n",
       "Tuscany_Red Blend                       1988\n",
       "Tuscany_Sangiovese                      1949\n",
       "California_Syrah                        1749\n",
       "California_Sauvignon Blanc              1675\n",
       "California_Red Blend                    1667\n",
       "Burgundy_Pinot Noir                     1443\n",
       "California_Merlot                       1296\n",
       "Mendoza Province_Malbec                 1265\n",
       "Washington_Cabernet Sauvignon           1255\n",
       "Champagne_Champagne Blend               1136\n",
       "Northern Spain_Tempranillo              1110\n",
       "Washington_Syrah                        1043\n",
       "Provence_Rosé                            947\n",
       "Mosel_Riesling                           921\n",
       "Beaujolais_Gamay                         892\n",
       "Bordeaux_Bordeaux style White Blend      886\n",
       "Douro_Portuguese Red                     819\n",
       "California_Bordeaux style Red Blend      819\n",
       "Washington_Red Blend                     793\n",
       "Tuscany_Sangiovese Grosso                695\n",
       "Loire Valley_Sauvignon Blanc             685\n",
       "Washington_Bordeaux style Red Blend      682\n",
       "New York_Riesling                        677\n",
       "Alsace_Riesling                          651\n",
       "Veneto_Glera                             641\n",
       "California_Petite Sirah                  633\n",
       "Washington_Merlot                        621\n",
       "Veneto_Corvina  Rondinella  Molinara     574\n",
       "Port_Port                                564\n",
       "Washington_Chardonnay                    557\n",
       "Northern Spain_Tempranillo Blend         524\n",
       "California_Sparkling Blend               513\n",
       "Veneto_Red Blend                         502\n",
       "Alentejano_Portuguese Red                495\n",
       "Northeastern Italy_Pinot Grigio          479\n",
       "California_Rosé                          466\n",
       "Oregon_Chardonnay                        458\n",
       "Mendoza Province_Cabernet Sauvignon      456\n",
       "California_Rhône style Red Blend         454\n",
       "Alsace_Gewürztraminer                    440\n",
       "Rhône Valley_Rhône style Red Blend       437\n",
       "Oregon_Pinot Gris                        436\n",
       "Catalonia_Sparkling Blend                429\n",
       "Piedmont_Barbera                         428\n",
       "South Australia_Shiraz                   416\n",
       "Alsace_Pinot Gris                        415\n",
       "Marlborough_Sauvignon Blanc              402\n",
       "California_Viognier                      398\n",
       "Southwest France_Malbec                  386\n",
       "Washington_Riesling                      379\n",
       "Sicily & Sardinia_Red Blend              376\n",
       "California_Grenache                      345\n",
       "Name: prov_var, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prov_var'] = df['province'] + '_' + df['variety']\n",
    "df['prov_var'].value_counts()[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d68ff",
   "metadata": {},
   "source": [
    "Theoretically, we could try to predict every single class presented in the data, but let's focus on a more limited number of the most populous of them. \n",
    "\n",
    "The code below creates **curated lists of red, white and sparking** wines of different varieties from different regions. These lists were manually and meticulously selected from the top 60 classes above to ensure we focus on the most popular varieties and regions. \n",
    "\n",
    "Later in this notebook we will focus only on red wines, but we'll also prepare the white and sparking lists for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb4a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_red = ['California_Pinot Noir',\n",
    "                'California_Cabernet Sauvignon',\n",
    "                'Oregon_Pinot Noir',  \n",
    "                'Washington_Cabernet Sauvignon',\n",
    "                'Washington_Syrah',                             \n",
    "                'Piedmont_Nebbiolo',\n",
    "                'Piedmont_Barbera',\n",
    "                'Tuscany_Sangiovese',\n",
    "                'Veneto_Corvina, Rondinella, Molinara',              \n",
    "                'Bordeaux_Bordeaux-style Red Blend',\n",
    "                'Burgundy_Pinot Noir',\n",
    "                'Beaujolais_Gamay',\n",
    "                'Rhône Valley_Rhône-style Red Blend',           \n",
    "                'Douro_Portuguese Red',\n",
    "                'Northern Spain_Tempranillo',                \n",
    "                'Mendoza Province_Malbec', \n",
    "                'South Australia_Shiraz']\n",
    "\n",
    "selected_white = ['California_Chardonnay', \n",
    "                  'Oregon_Chardonnay',\n",
    "                  'Oregon_Pinot Gris',\n",
    "                  'Washington_Riesling',\n",
    "                  'Mosel_Riesling',      \n",
    "                  'Burgundy_Chardonnay', \n",
    "                  'Bordeaux_Bordeaux-style White Blend',\n",
    "                  'Loire Valley_Sauvignon Blanc',\n",
    "                  'Alsace_Riesling',\n",
    "                  'Alsace_Gewürztraminer',\n",
    "                  'Alsace_Pinot Gris',\n",
    "                  'Northeastern Italy_Pinot Grigio',\n",
    "                  'Marlborough_Sauvignon Blanc']\n",
    "\n",
    "                  \n",
    "selected_spark = ['Champagne_Champagne Blend',\n",
    "                  'California_Sparkling Blend',\n",
    "                  'Veneto_Glera',\n",
    "                  'Catalonia_Sparkling Blend']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5dc71",
   "metadata": {},
   "source": [
    "Finally, we prepare **three training datasets** - with red, white and sparkling wines separately.\n",
    "\n",
    "Why separately? Mainly because when you \"blindly\" taste wine, you can usually know right away if it's red, white or sparkling. Also it's easier to explore and interpret the resutls when you separate these three.\n",
    "\n",
    "The code below creates the three datasets with the only columns we may need for training *id*, *description* and *prov_var*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa0d805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_select(lst):\n",
    "    return df[df.prov_var.isin(lst)][['id', 'description', 'prov_var']]\n",
    "\n",
    "df_red = df_select(selected_red)\n",
    "df_white = df_select(selected_white)\n",
    "df_spark = df_select(selected_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a17a6",
   "metadata": {},
   "source": [
    "## Red wines: further data explorationg and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b8754",
   "metadata": {},
   "source": [
    "The code below show the number of entries in each class. We can see that the **classes are imbalanced**; therefore, we decide to use ***f1_macro*** score to measure the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83e40b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California_Pinot Noir            6418\n",
       "California_Cabernet Sauvignon    5328\n",
       "Oregon_Pinot Noir                2560\n",
       "Piedmont_Nebbiolo                2478\n",
       "Tuscany_Sangiovese               1949\n",
       "Burgundy_Pinot Noir              1443\n",
       "Mendoza Province_Malbec          1265\n",
       "Washington_Cabernet Sauvignon    1255\n",
       "Northern Spain_Tempranillo       1110\n",
       "Washington_Syrah                 1043\n",
       "Beaujolais_Gamay                  892\n",
       "Douro_Portuguese Red              819\n",
       "Piedmont_Barbera                  428\n",
       "South Australia_Shiraz            416\n",
       "Name: prov_var, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red['prov_var'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91195d9",
   "metadata": {},
   "source": [
    "We will use *TfidfVectorizer* to learn vocabulary and idf from the predictor column (*description*). Note that this piece of code is just for exploration; it's not used in the actual training. \n",
    "\n",
    "We play with different *max_df* and *min_df* thresholds and **explore the vocabulary and stop words**. Using  *stop_words = 'english'* and limiting *max_df* to *0.16* helps avoid most frequent, but useless, descriptors from appearing in the results (see the stop words list below). We'll use this observation when we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550b672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words: {'ripe', 'cherry', 'flavors', 'wine', 'palate', 'drink', 'aromas', 'black', 'oak', 'berry', 'finish', 'red', 'fruit', 'tannins', 'acidity'}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2), max_df = 0.16, min_df = 1)\n",
    "vectorizer.fit(df_red['description'])\n",
    "\n",
    "#print('stop words count:', len(vectorizer.stop_words_))\n",
    "print('stop words:', vectorizer.stop_words_)\n",
    "#print('vocabulary size:', len(vectorizer.vocabulary_))\n",
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ecbe4",
   "metadata": {},
   "source": [
    "Finally, for convenience, we assign **numerical values for each class** and create *X* and *y* variables. We are ready for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb676e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Douro_Portuguese Red', 4], ['Oregon_Pinot Noir', 7], ['California_Cabernet Sauvignon', 2], ['Mendoza Province_Malbec', 5], ['California_Pinot Noir', 3], ['Beaujolais_Gamay', 0], ['Tuscany_Sangiovese', 11], ['Piedmont_Nebbiolo', 9], ['Piedmont_Barbera', 8], ['South Australia_Shiraz', 10], ['Burgundy_Pinot Noir', 1], ['Northern Spain_Tempranillo', 6], ['Washington_Syrah', 13], ['Washington_Cabernet Sauvignon', 12]]\n"
     ]
    }
   ],
   "source": [
    "df_red['prov_var_code'] = pd.Categorical(df_red.prov_var).codes\n",
    "class_map = df_red.drop_duplicates(['prov_var', 'prov_var_code'])[['prov_var', 'prov_var_code']]\n",
    "class_map = class_map.values.tolist()\n",
    "print(class_map)\n",
    "\n",
    "X = df_red['description']\n",
    "y = df_red['prov_var_code']\n",
    "#print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df26a2d",
   "metadata": {},
   "source": [
    "## MultinomialNB: training and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b52835",
   "metadata": {},
   "source": [
    "First, we train a **multinomial Naive Bayes classifier** as a baseline for our model. Using *GridSearchCV*, we try different parameter values for both *TfidfVectorizer* and *MultinomialNB* and display the best parameters and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1173abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "\n",
      "BEST PARAMETERS AND BEST SCORE:\n",
      " {'clf__alpha': 0.04, 'tfidf__max_df': 0.16, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'} 0.6882762678527033\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__ngram_range': [(1, 2), (2, 2)],\n",
    "    'tfidf__max_df': [0.1, 0.13, 0.16],\n",
    "    'tfidf__min_df': [0.0, 0.001, 1],\n",
    "    'clf__alpha': np.arange(0.03, 0.05, 0.01)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(pipe, parameters, scoring = \"f1_macro\", cv = 3, verbose = 1)\n",
    "gs_clf.fit(X, y)\n",
    "\n",
    "print('\\nBEST PARAMETERS AND BEST SCORE:\\n', gs_clf.best_params_, gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2591445",
   "metadata": {},
   "source": [
    "Now we **retrain the model with the best parameters** from the grid search above. We will use this model to display the main descriptor for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dccd8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2), max_df = 0.16, min_df = 0.001)\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "clf = MultinomialNB(alpha = 0.04).fit(X_vect, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed97071",
   "metadata": {},
   "source": [
    "The code below prints the **top 10 best descriptors for each class**. Top descriptors are selected using *feature_log_prob_* (empirical log probability of descriptors given a class). \n",
    "\n",
    "This is the main result of our work - let's review it carefully! Not all of the descriptors are useful and make sense, but if we filter them out, we get quite satisfying results. For example, when you have Oregon Pinot Noir in your hand, you most likely experience *cherry fruit, strawberry, chocolate* and the wine might be *light and tart*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfed01cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Douro_Portuguese Red\n",
      "fruits, wood, aging, rich, structure, dense, black fruits, ready, firm, dark, \n",
      "\n",
      "Oregon_Pinot Noir\n",
      "cherry fruit, light, tart, vineyard, strawberry, new, raspberry, chocolate, bit, pretty, \n",
      "\n",
      "California_Cabernet Sauvignon\n",
      "blackberry, currant, dry, soft, blackberries, cab, cedar, chocolate, rich, cassis, \n",
      "\n",
      "Mendoza Province_Malbec\n",
      "plum, blackberry, herbal, feels, notes, nose, berry aromas, jammy, oaky, berry flavors, \n",
      "\n",
      "California_Pinot Noir\n",
      "cola, raspberry, silky, cherries, dry, texture, light, nose, vineyard, cranberry, \n",
      "\n",
      "Beaujolais_Gamay\n",
      "fruits, fruity, structure, firm, rich, structured, ready, ready drink, juicy, character, \n",
      "\n",
      "Tuscany_Sangiovese\n",
      "alongside, offers, palate offers, black cherry, spice, leather, underbrush, opens, delivers, espresso, \n",
      "\n",
      "Piedmont_Nebbiolo\n",
      "spice, licorice, offers, alongside, barolo, firm, leather, palate offers, opens, rose, \n",
      "\n",
      "Piedmont_Barbera\n",
      "spice, bright, asti, alongside, fresh, offers, black cherry, blackberry, skinned, alba, \n",
      "\n",
      "South Australia_Shiraz\n",
      "bodied, vanilla, notes, creamy, finish drink, hints, long, barossa, supple, 2025, \n",
      "\n",
      "Burgundy_Pinot Noir\n",
      "fruits, structure, firm, red fruits, aging, wood, rich, structured, character, soft, \n",
      "\n",
      "Northern Spain_Tempranillo\n",
      "plum, feels, rioja, blackberry, tannic, notes, vanilla, berry aromas, nose, oaky, \n",
      "\n",
      "Washington_Syrah\n",
      "fruit flavors, notes, barrel, meat, smoked meat, herb, dark, smoked, coffee, vineyard, \n",
      "\n",
      "Washington_Cabernet Sauvignon\n",
      "barrel, fruit flavors, herb, dark, notes, herbs, spice, coffee, vanilla, lead, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for cl in class_map:\n",
    "    print(cl[0])\n",
    "    \n",
    "    feature_map = list(zip(feature_names, clf.feature_log_prob_[cl[1]]))\n",
    "    \n",
    "    for f in sorted(feature_map, key = lambda t: t[1], reverse = True)[:10]:\n",
    "        print(f[0], end = ', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac58ad",
   "metadata": {},
   "source": [
    "Here is how we can **use the model for prediction**. In other words, here is how we \"blind taste\" with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5411e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['California_Pinot Noir', 'Washington_Syrah']\n"
     ]
    }
   ],
   "source": [
    "test_input = ['Bright strawberry and cherry aromas and flavors. Light wine with a tart finish.',\n",
    "              'Dark fruit flavors with notes of smoked meat, dried hers and earth.']\n",
    "\n",
    "result = list(clf.predict(vectorizer.transform(test_input)))\n",
    "print(list(c[0] for c in class_map if c[1] in result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57967e1c",
   "metadata": {},
   "source": [
    "## SGDClassifier: training and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a49685",
   "metadata": {},
   "source": [
    "We will train a few more models using **SGDClassifier** and compare them with the baseline above. Similarly, we use *GridSearchCV* to go over different parameter values for both *TfidfVectorizer* and *SGDClassifier* and display the best parameters and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eee4cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "\n",
      "BEST PARAMETERS AND BEST SCORE:\n",
      " {'clf__loss': 'modified_huber', 'clf__max_iter': 5, 'clf__penalty': 'l2', 'clf__tol': None, 'tfidf__max_df': 0.1, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None} 0.7281575261864273\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()), ('clf', SGDClassifier())])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__ngram_range': [(1, 2), (2, 2)],\n",
    "    'tfidf__max_df': [0.1, 0.13, 0.16],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'clf__loss': ['hinge', 'modified_huber'],\n",
    "    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'clf__max_iter': [5],\n",
    "    'clf__tol': [None]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(pipe, parameters, scoring = \"f1_macro\", cv = 3, verbose = 1)\n",
    "gs_clf.fit(X, y)\n",
    "\n",
    "print('\\nBEST PARAMETERS AND BEST SCORE:\\n', gs_clf.best_params_, gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91100f7",
   "metadata": {},
   "source": [
    "Note that this model gives us a little higher score.\n",
    "\n",
    "Similarly to before, we **retrain the model with the best parameters** from the grid search above. We will use this model to display the main descriptor for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e80107a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = None, ngram_range = (1, 2), max_df = 0.1, min_df = 0.001)\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "clf = SGDClassifier(loss = 'modified_huber', penalty = 'l2', max_iter = 5, tol = None).fit(X_vect, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8c111",
   "metadata": {},
   "source": [
    "Similarly to before, we now print the **top 10 best descriptors for each class**. Top descriptors are selected using *coef_* (weights assigned to the descriptors). \n",
    "\n",
    "Here we see more descriptors that are not useful and don't make sense than in the previous model. For example, for Oregon Pinot Noir we can only use *cherry fruit* as a meaningful descriptor. Due to this, let's use the previous model as our final model for making predictions and generating descriptiors, even though this one give a slightly higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06c90ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Douro_Portuguese Red\n",
      "quinta, superior, touriga, river, black currant, second wine, smooth, mineral, black plum, port, \n",
      "\n",
      "Oregon_Pinot Noir\n",
      "cherry fruit, cuvée, ava, now through, pinots, willamette, reserve, streaked, highlights, gracefully, \n",
      "\n",
      "California_Cabernet Sauvignon\n",
      "cab, blackberries, napa, cedar, currant, mountain, blackberry cherry, blackberry and, cabs, black currants, \n",
      "\n",
      "Mendoza Province_Malbec\n",
      "malbecs, tartaric, herbal, sticky, the bouquet, salty, palate is, saturated, generic, weedy, \n",
      "\n",
      "California_Pinot Noir\n",
      "silky, cola, tea, pomegranate, cherries, raspberries, earthy, pink, raspberry and, sagebrush, \n",
      "\n",
      "Beaujolais_Gamay\n",
      "banana, cru, cherry fruits, cru wine, cherry flavors, granite, months, red cherry, cherry fruit, the cru, \n",
      "\n",
      "Tuscany_Sangiovese\n",
      "chianti, brunello, riserva, mediterranean, tuscan, rosso, wild cherry, underbrush, savory herb, palate offers, \n",
      "\n",
      "Piedmont_Nebbiolo\n",
      "barolo, barbaresco, rose, drink after, cru, camphor, tar, ginger, licorice, hazelnut, \n",
      "\n",
      "Piedmont_Barbera\n",
      "asti, alba, informal, here, skinned berry, enjoy through, pair, of with, cherry blackberry, pasta, \n",
      "\n",
      "South Australia_Shiraz\n",
      "barossa, drink now, supple, creamy, now 2025, vanilla, slightly, finish drink, textured, 2025, \n",
      "\n",
      "Burgundy_Pinot Noir\n",
      "premier, drink from, beaune, nuits, perfumed, strawberry, grand cru, red berry, red currant, premier cru, \n",
      "\n",
      "Northern Spain_Tempranillo\n",
      "rioja, ribera, crianza, tannic, plum and, healthy, hard, feels, reserva, baked, \n",
      "\n",
      "Washington_Syrah\n",
      "boushey, viognier, grenache, flowers, savory flavors, smoked meat, les, sappy, yakima, huckleberry, \n",
      "\n",
      "Washington_Cabernet Sauvignon\n",
      "cassis, champoux, herb, herbs, bordeaux, red mountain, includes, woodspice, pure, merlot, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for cl in class_map:\n",
    "    print(cl[0])\n",
    "    \n",
    "    feature_map = list(zip(feature_names, clf.coef_[cl[1]]))\n",
    "    \n",
    "    for f in sorted(feature_map, key = lambda t: t[1], reverse = True)[:10]:\n",
    "        print(f[0], end = ', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63512ff2",
   "metadata": {},
   "source": [
    "## Next steps and improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108a93f",
   "metadata": {},
   "source": [
    "To improve the models (especially the second one) we can better clean and normalize the data before training (using NLTK, for example) to avoid cases like \"the cru\"/\"this cru\" and \"blackberries\"/\"blackberry\". \n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c41709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
